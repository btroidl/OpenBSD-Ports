Index: crypto/sha/asm/sha512-armv8.pl
--- crypto/sha/asm/sha512-armv8.pl.orig
+++ crypto/sha/asm/sha512-armv8.pl
@@ -199,14 +199,8 @@ $code.=<<___;
 .align	6
 $func:
 #ifndef	__KERNEL__
-# ifdef	__ILP32__
-	ldrsw	x16,.LOPENSSL_armcap_P
-# else
-	ldr	x16,.LOPENSSL_armcap_P
-# endif
-	adr	x17,.LOPENSSL_armcap_P
-	add	x16,x16,x17
-	ldr	w16,[x16]
+	adrp	x16,OPENSSL_armcap_P
+	ldr	w16,[x16,#:lo12:OPENSSL_armcap_P]
 ___
 $code.=<<___	if ($SZ==4);
 	tst	w16,#ARMV8_SHA256
@@ -236,7 +230,8 @@ $code.=<<___;
 	ldp	$E,$F,[$ctx,#4*$SZ]
 	add	$num,$inp,$num,lsl#`log(16*$SZ)/log(2)`	// end of input
 	ldp	$G,$H,[$ctx,#6*$SZ]
-	adr	$Ktbl,.LK$BITS
+	adrp	$Ktbl,.LK$BITS
+	add	$Ktbl,$Ktbl,:lo12:.LK$BITS
 	stp	$ctx,$num,[x29,#96]
 
 .Loop:
@@ -286,6 +281,8 @@ $code.=<<___;
 	ret
 .size	$func,.-$func
 
+.rodata
+
 .align	6
 .type	.LK$BITS,%object
 .LK$BITS:
@@ -365,6 +362,8 @@ $code.=<<___;
 #endif
 .asciz	"SHA$BITS block transform for ARMv8, CRYPTOGAMS by <appro\@openssl.org>"
 .align	2
+
+.text
 ___
 
 if ($SZ==4) {
@@ -385,7 +384,8 @@ sha256_block_armv8:
 	add		x29,sp,#0
 
 	ld1.32		{$ABCD,$EFGH},[$ctx]
-	adr		$Ktbl,.LK256
+	adrp		$Ktbl,.LK256
+	add		$Ktbl,$Ktbl,:lo12:.LK256
 
 .Loop_hw:
 	ld1		{@MSG[0]-@MSG[3]},[$inp],#64
@@ -648,7 +648,8 @@ sha256_block_neon:
 	mov	x29, sp
 	sub	sp,sp,#16*4
 
-	adr	$Ktbl,.LK256
+	adrp	$Ktbl,.LK256
+	add	$Ktbl,$Ktbl,:lo12:.LK256
 	add	$num,$inp,$num,lsl#6	// len to point at the end of inp
 
 	ld1.8	{@X[0]},[$inp], #16
@@ -761,7 +762,8 @@ sha512_block_armv8:
 	ld1		{@MSG[4]-@MSG[7]},[$inp],#64
 
 	ld1.64		{@H[0]-@H[3]},[$ctx]		// load context
-	adr		$Ktbl,.LK512
+	adrp		$Ktbl,.LK512
+	add		$Ktbl,$Ktbl,:lo12:.LK512
 
 	rev64		@MSG[0],@MSG[0]
 	rev64		@MSG[1],@MSG[1]
