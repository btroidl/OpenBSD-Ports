Index: pregenerated/ecp_nistz256-armv8-linux64.S
--- pregenerated/ecp_nistz256-armv8-linux64.S.orig
+++ pregenerated/ecp_nistz256-armv8-linux64.S
@@ -12,7 +12,7 @@
 #if defined(__aarch64__)
 #include <GFp/arm_arch.h>
 
-.text
+.section	.rodata
 .align	5
 .Lpoly:
 .quad	0xffffffffffffffff,0x00000000ffffffff,0x0000000000000000,0xffffffff00000001
@@ -22,6 +22,7 @@
 .quad	1,0,0,0
 .byte	69,67,80,95,78,73,83,84,90,50,53,54,32,102,111,114,32,65,82,77,118,56,44,32,67,82,89,80,84,79,71,65,77,83,32,98,121,32,60,97,112,112,114,111,64,111,112,101,110,115,115,108,46,111,114,103,62,0
 .align	2
+.text
 
 // void	GFp_nistz256_mul_mont(BN_ULONG x0[4],const BN_ULONG x1[4],
 //					     const BN_ULONG x2[4]);
@@ -37,8 +38,10 @@ GFp_nistz256_mul_mont:
 	ldr	x3,[x2]		// bp[0]
 	ldp	x4,x5,[x1]
 	ldp	x6,x7,[x1,#16]
-	ldr	x12,.Lpoly+8
-	ldr	x13,.Lpoly+24
+	adrp	x13,.Lpoly
+	add	x13,x13,:lo12:.Lpoly
+	ldr	x12,[x13,#8]
+	ldr	x13,[x13,#24]
 
 	bl	__ecp_nistz256_mul_mont
 
@@ -59,8 +62,10 @@ GFp_nistz256_sqr_mont:
 
 	ldp	x4,x5,[x1]
 	ldp	x6,x7,[x1,#16]
-	ldr	x12,.Lpoly+8
-	ldr	x13,.Lpoly+24
+	adrp	x13,.Lpoly
+	add	x13,x13,:lo12:.Lpoly
+	ldr	x12,[x13,#8]
+	ldr	x13,[x13,#24]
 
 	bl	__ecp_nistz256_sqr_mont
 
@@ -83,8 +88,10 @@ GFp_nistz256_add:
 	ldp	x8,x9,[x2]
 	ldp	x16,x17,[x1,#16]
 	ldp	x10,x11,[x2,#16]
-	ldr	x12,.Lpoly+8
-	ldr	x13,.Lpoly+24
+	adrp	x13,.Lpoly
+	add	x13,x13,:lo12:.Lpoly
+	ldr	x12,[x13,#8]
+	ldr	x13,[x13,#24]
 
 	bl	__ecp_nistz256_add
 
@@ -106,8 +113,10 @@ GFp_nistz256_neg:
 	mov	x15,xzr
 	mov	x16,xzr
 	mov	x17,xzr
-	ldr	x12,.Lpoly+8
-	ldr	x13,.Lpoly+24
+	adrp	x13,.Lpoly
+	add	x13,x13,:lo12:.Lpoly
+	ldr	x12,[x13,#8]
+	ldr	x13,[x13,#24]
 
 	bl	__ecp_nistz256_sub_from
 
@@ -501,9 +510,11 @@ GFp_nistz256_point_double:
 	mov	x21,x0
 	ldp	x16,x17,[x1,#48]
 	mov	x22,x1
-	ldr	x12,.Lpoly+8
+	adrp	x13,.Lpoly
+	add	x13,x13,:lo12:.Lpoly
+	ldr	x12,[x13,#8]
 	mov	x8,x14
-	ldr	x13,.Lpoly+24
+	ldr	x13,[x13,#24]
 	mov	x9,x15
 	ldp	x4,x5,[x22,#64]	// forward load for p256_sqr_mont
 	mov	x10,x16
@@ -642,8 +653,10 @@ GFp_nistz256_point_add_affine:
 	mov	x21,x0
 	mov	x22,x1
 	mov	x23,x2
-	ldr	x12,.Lpoly+8
-	ldr	x13,.Lpoly+24
+	adrp	x13,.Lpoly
+	add	x13,x13,:lo12:.Lpoly
+	ldr	x12,[x13,#8]
+	ldr	x13,[x13,#24]
 
 	ldp	x4,x5,[x1,#64]	// in1_z
 	ldp	x6,x7,[x1,#64+16]
@@ -789,7 +802,8 @@ GFp_nistz256_point_add_affine:
 	ldp	x10,x11,[x23,#0+48]
 	stp	x14,x15,[x21,#0]
 	stp	x16,x17,[x21,#0+16]
-	adr	x23,.Lone_mont-64
+	adrp	x23,.Lone_mont-64
+	add	x23,x23,:lo12:.Lone_mont-64
 	ldp	x14,x15,[x22,#32]	// in1
 	cmp	x24,#0			// !, remember?
 	ldp	x16,x17,[x22,#32+16]
